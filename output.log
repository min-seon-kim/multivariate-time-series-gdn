nohup: ignoring input
Running seed 1...
Running seed 2...
Running seed 4...
Running seed 3...
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01013495, ACU_loss:19.88477745)
epoch (0 / 50) (Loss:0.00993541, ACU_loss:19.49326616)
epoch (0 / 50) (Loss:0.01073754, ACU_loss:21.06704438)
epoch (0 / 50) (Loss:0.01141172, ACU_loss:22.38979395)
epoch (1 / 50) (Loss:0.00582797, ACU_loss:11.43448481)
epoch (1 / 50) (Loss:0.00606451, ACU_loss:11.89855942)
epoch (1 / 50) (Loss:0.00471947, ACU_loss:9.25960980)
epoch (1 / 50) (Loss:0.00493428, ACU_loss:9.68106553)
epoch (2 / 50) (Loss:0.00601150, ACU_loss:11.79455522)
epoch (2 / 50) (Loss:0.00596551, ACU_loss:11.70432766)
epoch (2 / 50) (Loss:0.00448249, ACU_loss:8.79464824)
epoch (2 / 50) (Loss:0.00524873, ACU_loss:10.29801190)
epoch (3 / 50) (Loss:0.00581335, ACU_loss:11.40579273)
epoch (3 / 50) (Loss:0.00613477, ACU_loss:12.03641836)
epoch (3 / 50) (Loss:0.00440936, ACU_loss:8.65115497)
epoch (3 / 50) (Loss:0.00628437, ACU_loss:12.32993970)
epoch (4 / 50) (Loss:0.00587617, ACU_loss:11.52904311)
epoch (4 / 50) (Loss:0.00602874, ACU_loss:11.82837901)
epoch (4 / 50) (Loss:0.00591731, ACU_loss:11.60976328)
epoch (4 / 50) (Loss:0.00628273, ACU_loss:12.32672200)
epoch (5 / 50) (Loss:0.00605247, ACU_loss:11.87493836)
epoch (5 / 50) (Loss:0.00610148, ACU_loss:11.97111138)
epoch (5 / 50) (Loss:0.00573454, ACU_loss:11.25116411)
epoch (5 / 50) (Loss:0.00625758, ACU_loss:12.27737109)
epoch (6 / 50) (Loss:0.00612028, ACU_loss:12.00799770)
epoch (6 / 50) (Loss:0.00576057, ACU_loss:11.30224593)
epoch (6 / 50) (Loss:0.00576840, ACU_loss:11.31760973)
epoch (6 / 50) (Loss:0.00621113, ACU_loss:12.18624470)
epoch (7 / 50) (Loss:0.00616512, ACU_loss:12.09596385)
epoch (7 / 50) (Loss:0.00604435, ACU_loss:11.85900701)
epoch (7 / 50) (Loss:0.00572627, ACU_loss:11.23494961)
epoch (7 / 50) (Loss:0.00630316, ACU_loss:12.36680474)
epoch (8 / 50) (Loss:0.00625274, ACU_loss:12.26788240)
epoch (8 / 50) (Loss:0.00578031, ACU_loss:11.34097292)
epoch (8 / 50) (Loss:0.00631413, ACU_loss:12.38832790)
epoch (8 / 50) (Loss:0.00631889, ACU_loss:12.39765867)
epoch (9 / 50) (Loss:0.00617261, ACU_loss:12.11066260)
epoch (9 / 50) (Loss:0.00591782, ACU_loss:11.61075799)
epoch (9 / 50) (Loss:0.00631509, ACU_loss:12.39019995)
epoch (9 / 50) (Loss:0.00643859, ACU_loss:12.63250603)
epoch (10 / 50) (Loss:0.00625918, ACU_loss:12.28051261)
epoch (10 / 50) (Loss:0.00620187, ACU_loss:12.16806820)
epoch (10 / 50) (Loss:0.00571540, ACU_loss:11.21361243)
epoch (10 / 50) (Loss:0.00652896, ACU_loss:12.80981824)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.1766848816029144
Precision: 0.9603960396039604
Recall: 0.09729187562688064
Accuracy: 0.9476700434153401
AUC: 0.6037284972006571

epoch (11 / 50) (Loss:0.00579076, ACU_loss:11.36147919)
epoch (11 / 50) (Loss:0.00650050, ACU_loss:12.75397948)
epoch (11 / 50) (Loss:0.00636896, ACU_loss:12.49590445)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.26356589147286824
Precision: 0.9329268292682927
Recall: 0.1534603811434303
Accuracy: 0.950506512301013
AUC: 0.6982063033923

epoch (12 / 50) (Loss:0.00579894, ACU_loss:11.37751092)
epoch (12 / 50) (Loss:0.00628461, ACU_loss:12.33040482)
epoch (13 / 50) (Loss:0.00594752, ACU_loss:11.66902751)
epoch (13 / 50) (Loss:0.00634048, ACU_loss:12.44003116)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.25476603119584057
Precision: 0.9363057324840764
Recall: 0.14744232698094284
Accuracy: 0.9502170767004342
AUC: 0.6489496133073012

epoch (14 / 50) (Loss:0.00631805, ACU_loss:12.39601283)
epoch (15 / 50) (Loss:0.00622201, ACU_loss:12.20757467)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.28665568369028005
Precision: 0.8018433179723502
Recall: 0.17452357071213642
Accuracy: 0.9498697539797395
AUC: 0.7256420323755391

Running seed 5...
Running seed 6...
Running seed 7...
Running seed 8...
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:207: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01015874, ACU_loss:19.93144995)
epoch (0 / 50) (Loss:0.01082377, ACU_loss:21.23623624)
epoch (0 / 50) (Loss:0.01178051, ACU_loss:23.11336251)
epoch (0 / 50) (Loss:0.01253520, ACU_loss:24.59406440)
epoch (1 / 50) (Loss:0.00493201, ACU_loss:9.67661062)
epoch (1 / 50) (Loss:0.00609150, ACU_loss:11.95152010)
epoch (1 / 50) (Loss:0.00503534, ACU_loss:9.87934480)
epoch (1 / 50) (Loss:0.00566851, ACU_loss:11.12161570)
epoch (2 / 50) (Loss:0.00462249, ACU_loss:9.06932986)
epoch (2 / 50) (Loss:0.00637670, ACU_loss:12.51108277)
epoch (2 / 50) (Loss:0.00536775, ACU_loss:10.53153310)
epoch (2 / 50) (Loss:0.00456660, ACU_loss:8.95966876)
epoch (3 / 50) (Loss:0.00453796, ACU_loss:8.90348528)
epoch (3 / 50) (Loss:0.00653771, ACU_loss:12.82698833)
epoch (3 / 50) (Loss:0.00451766, ACU_loss:8.86365843)
epoch (3 / 50) (Loss:0.00530995, ACU_loss:10.41812503)
epoch (4 / 50) (Loss:0.00439985, ACU_loss:8.63251257)
epoch (4 / 50) (Loss:0.00645360, ACU_loss:12.66196364)
epoch (4 / 50) (Loss:0.00533253, ACU_loss:10.46242407)
epoch (4 / 50) (Loss:0.00451666, ACU_loss:8.86169174)
epoch (5 / 50) (Loss:0.00433182, ACU_loss:8.49902693)
epoch (5 / 50) (Loss:0.00649505, ACU_loss:12.74329034)
epoch (5 / 50) (Loss:0.00450503, ACU_loss:8.83886549)
epoch (5 / 50) (Loss:0.00527710, ACU_loss:10.35366749)
epoch (6 / 50) (Loss:0.00443753, ACU_loss:8.70643533)
epoch (6 / 50) (Loss:0.00453828, ACU_loss:8.90410445)
epoch (6 / 50) (Loss:0.00649428, ACU_loss:12.74177481)
epoch (6 / 50) (Loss:0.00527143, ACU_loss:10.34253848)
epoch (7 / 50) (Loss:0.00444241, ACU_loss:8.71600350)
epoch (7 / 50) (Loss:0.00453799, ACU_loss:8.90353966)
epoch (7 / 50) (Loss:0.00524325, ACU_loss:10.28724755)
epoch (7 / 50) (Loss:0.00643637, ACU_loss:12.62814964)
epoch (8 / 50) (Loss:0.00441681, ACU_loss:8.66579018)
epoch (8 / 50) (Loss:0.00664673, ACU_loss:13.04087867)
epoch (8 / 50) (Loss:0.00509220, ACU_loss:9.99090520)
epoch (8 / 50) (Loss:0.00452631, ACU_loss:8.88061725)
epoch (9 / 50) (Loss:0.00453899, ACU_loss:8.90550408)
epoch (9 / 50) (Loss:0.00462821, ACU_loss:9.08053828)
epoch (9 / 50) (Loss:0.00663590, ACU_loss:13.01963870)
epoch (9 / 50) (Loss:0.00512061, ACU_loss:10.04664256)
epoch (10 / 50) (Loss:0.00470730, ACU_loss:9.23571310)
epoch (10 / 50) (Loss:0.00671113, ACU_loss:13.16723147)
epoch (10 / 50) (Loss:0.00454649, ACU_loss:8.92021767)
epoch (10 / 50) (Loss:0.00512211, ACU_loss:10.04958013)
epoch (11 / 50) (Loss:0.00456109, ACU_loss:8.94886474)
epoch (11 / 50) (Loss:0.00468940, ACU_loss:9.20060880)
epoch (11 / 50) (Loss:0.00684332, ACU_loss:13.42659007)
epoch (11 / 50) (Loss:0.00514151, ACU_loss:10.08764717)
epoch (12 / 50) (Loss:0.00453857, ACU_loss:8.90467636)
epoch (12 / 50) (Loss:0.00479459, ACU_loss:9.40699323)
epoch (12 / 50) (Loss:0.00683225, ACU_loss:13.40488092)
epoch (12 / 50) (Loss:0.00508637, ACU_loss:9.97944919)
epoch (13 / 50) (Loss:0.00460968, ACU_loss:9.04419723)
epoch (13 / 50) (Loss:0.00481907, ACU_loss:9.45501633)
epoch (13 / 50) (Loss:0.00507623, ACU_loss:9.95955886)
epoch (13 / 50) (Loss:0.00685135, ACU_loss:13.44235283)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.3786793953858393
Precision: 0.9153846153846154
Recall: 0.238716148445336
Accuracy: 0.9547901591895803
AUC: 0.7252754701011747

epoch (14 / 50) (Loss:0.00679482, ACU_loss:13.33143215)
epoch (14 / 50) (Loss:0.00474471, ACU_loss:9.30912137)
epoch (14 / 50) (Loss:0.00507205, ACU_loss:9.95136241)
epoch (15 / 50) (Loss:0.00687144, ACU_loss:13.48176433)
epoch (15 / 50) (Loss:0.00483676, ACU_loss:9.48971415)
epoch (15 / 50) (Loss:0.00509735, ACU_loss:10.00100776)
epoch (16 / 50) (Loss:0.00696371, ACU_loss:13.66279077)
epoch (16 / 50) (Loss:0.00477377, ACU_loss:9.36613604)
epoch (16 / 50) (Loss:0.00507764, ACU_loss:9.96233467)
epoch (17 / 50) (Loss:0.00669160, ACU_loss:13.12891885)
epoch (17 / 50) (Loss:0.00477067, ACU_loss:9.36005221)
epoch (17 / 50) (Loss:0.00510226, ACU_loss:10.01063327)
epoch (18 / 50) (Loss:0.00507932, ACU_loss:9.96561701)
epoch (18 / 50) (Loss:0.00475872, ACU_loss:9.33660078)
epoch (18 / 50) (Loss:0.00755262, ACU_loss:14.81823641)
epoch (19 / 50) (Loss:0.00508652, ACU_loss:9.97974271)
epoch (19 / 50) (Loss:0.00476843, ACU_loss:9.35565066)
epoch (19 / 50) (Loss:0.00729301, ACU_loss:14.30887869)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.2888700084961767
Precision: 0.9444444444444444
Recall: 0.17051153460381144
Accuracy: 0.9515484804630969
AUC: 0.7731723244435358

epoch (20 / 50) (Loss:0.00510252, ACU_loss:10.01115037)
epoch (20 / 50) (Loss:0.00719219, ACU_loss:14.11106808)
epoch (21 / 50) (Loss:0.00511772, ACU_loss:10.04097113)
epoch (21 / 50) (Loss:0.00743718, ACU_loss:14.59175537)
epoch (22 / 50) (Loss:0.00506540, ACU_loss:9.93831618)
epoch (22 / 50) (Loss:0.00719638, ACU_loss:14.11929499)
epoch (23 / 50) (Loss:0.00507858, ACU_loss:9.96417329)
epoch (23 / 50) (Loss:0.00715325, ACU_loss:14.03467824)
epoch (24 / 50) (Loss:0.00504530, ACU_loss:9.89887669)
epoch (24 / 50) (Loss:0.00709435, ACU_loss:13.91911144)
epoch (25 / 50) (Loss:0.00510596, ACU_loss:10.01790060)
epoch (25 / 50) (Loss:0.00667979, ACU_loss:13.10574759)
epoch (26 / 50) (Loss:0.00508450, ACU_loss:9.97579693)
epoch (26 / 50) (Loss:0.00724175, ACU_loss:14.20830563)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
epoch (27 / 50) (Loss:0.00509197, ACU_loss:9.99043658)
=========================** Result **============================

F1 score: 0.34340222575516693
Precision: 0.8275862068965517
Recall: 0.21664994984954863
Accuracy: 0.9521852387843704
AUC: 0.6666635241761653

epoch (28 / 50) (Loss:0.00503490, ACU_loss:9.87848005)
epoch (29 / 50) (Loss:0.00503893, ACU_loss:9.88638867)
epoch (30 / 50) (Loss:0.00503984, ACU_loss:9.88815780)
epoch (31 / 50) (Loss:0.00502704, ACU_loss:9.86305512)
epoch (32 / 50) (Loss:0.00502682, ACU_loss:9.86262151)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.272572402044293
Precision: 0.903954802259887
Recall: 0.160481444332999
Accuracy: 0.9505643994211288
AUC: 0.7076693281712689

Running seed 9...
Running seed 11...
Running seed 10...
Running seed 12...
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01136965, ACU_loss:22.30724624)
epoch (0 / 50) (Loss:0.01122411, ACU_loss:22.02171324)
epoch (0 / 50) (Loss:0.01160700, ACU_loss:22.77293569)
epoch (0 / 50) (Loss:0.01028093, ACU_loss:20.17118614)
epoch (1 / 50) (Loss:0.00561541, ACU_loss:11.01742594)
epoch (1 / 50) (Loss:0.00618616, ACU_loss:12.13723911)
epoch (1 / 50) (Loss:0.00610546, ACU_loss:11.97890886)
epoch (1 / 50) (Loss:0.00523320, ACU_loss:10.26754450)
epoch (2 / 50) (Loss:0.00614800, ACU_loss:12.06237694)
epoch (2 / 50) (Loss:0.00533165, ACU_loss:10.46070076)
epoch (2 / 50) (Loss:0.00631887, ACU_loss:12.39761652)
epoch (2 / 50) (Loss:0.00462770, ACU_loss:9.07954282)
epoch (3 / 50) (Loss:0.00594053, ACU_loss:11.65532609)
epoch (3 / 50) (Loss:0.00529953, ACU_loss:10.39767969)
epoch (3 / 50) (Loss:0.00436966, ACU_loss:8.57326634)
epoch (3 / 50) (Loss:0.00626180, ACU_loss:12.28565054)
epoch (4 / 50) (Loss:0.00617962, ACU_loss:12.12441249)
epoch (4 / 50) (Loss:0.00530597, ACU_loss:10.41031598)
epoch (4 / 50) (Loss:0.00441338, ACU_loss:8.65905183)
epoch (4 / 50) (Loss:0.00634133, ACU_loss:12.44169060)
epoch (5 / 50) (Loss:0.00609008, ACU_loss:11.94874419)
epoch (5 / 50) (Loss:0.00529282, ACU_loss:10.38450514)
epoch (5 / 50) (Loss:0.00434106, ACU_loss:8.51715531)
epoch (5 / 50) (Loss:0.00645731, ACU_loss:12.66923455)
epoch (6 / 50) (Loss:0.00606553, ACU_loss:11.90056748)
epoch (6 / 50) (Loss:0.00533532, ACU_loss:10.46789153)
epoch (6 / 50) (Loss:0.00635065, ACU_loss:12.45997414)
epoch (6 / 50) (Loss:0.00426936, ACU_loss:8.37648271)
epoch (7 / 50) (Loss:0.00615228, ACU_loss:12.07078187)
epoch (7 / 50) (Loss:0.00523855, ACU_loss:10.27802618)
epoch (7 / 50) (Loss:0.00641876, ACU_loss:12.59360550)
epoch (7 / 50) (Loss:0.00423495, ACU_loss:8.30897239)
epoch (8 / 50) (Loss:0.00621987, ACU_loss:12.20338238)
epoch (8 / 50) (Loss:0.00522525, ACU_loss:10.25194002)
epoch (8 / 50) (Loss:0.00645999, ACU_loss:12.67449553)
epoch (8 / 50) (Loss:0.00425459, ACU_loss:8.34750088)
epoch (9 / 50) (Loss:0.00614710, ACU_loss:12.06060667)
epoch (9 / 50) (Loss:0.00517595, ACU_loss:10.15520918)
epoch (9 / 50) (Loss:0.00666806, ACU_loss:13.08274246)
epoch (9 / 50) (Loss:0.00449481, ACU_loss:8.81880833)
epoch (10 / 50) (Loss:0.00600642, ACU_loss:11.78459559)
epoch (10 / 50) (Loss:0.00516774, ACU_loss:10.13909789)
epoch (10 / 50) (Loss:0.00681322, ACU_loss:13.36753187)
epoch (10 / 50) (Loss:0.00463549, ACU_loss:9.09483068)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.27249357326478146
Precision: 0.9352941176470588
Recall: 0.15947843530591777
Accuracy: 0.9508538350217076
AUC: 0.711722401508494

epoch (11 / 50) (Loss:0.00514229, ACU_loss:10.08916804)
epoch (11 / 50) (Loss:0.00681014, ACU_loss:13.36148626)
epoch (11 / 50) (Loss:0.00466840, ACU_loss:9.15940404)
epoch (12 / 50) (Loss:0.00509904, ACU_loss:10.00431057)
epoch (12 / 50) (Loss:0.00699306, ACU_loss:13.72037554)
epoch (12 / 50) (Loss:0.00475522, ACU_loss:9.32974481)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.12417685794920037
Precision: 1.0
Recall: 0.06619859578736209
Accuracy: 0.9461070911722141
AUC: 0.6089759017807816

epoch (13 / 50) (Loss:0.00513494, ACU_loss:10.07476077)
epoch (13 / 50) (Loss:0.00476092, ACU_loss:9.34092055)
epoch (14 / 50) (Loss:0.00510012, ACU_loss:10.00642595)
epoch (14 / 50) (Loss:0.00471312, ACU_loss:9.24714235)
epoch (15 / 50) (Loss:0.00508164, ACU_loss:9.97018374)
epoch (15 / 50) (Loss:0.00474551, ACU_loss:9.31068541)
epoch (16 / 50) (Loss:0.00480655, ACU_loss:9.43044721)
epoch (16 / 50) (Loss:0.00508880, ACU_loss:9.98421795)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.21554770318021202
Precision: 0.9037037037037037
Recall: 0.12236710130391174
Accuracy: 0.9485962373371924
AUC: 0.7290745562649368

epoch (17 / 50) (Loss:0.00508224, ACU_loss:9.97135623)
epoch (18 / 50) (Loss:0.00507111, ACU_loss:9.94951997)
epoch (19 / 50) (Loss:0.00508386, ACU_loss:9.97453563)
epoch (20 / 50) (Loss:0.00507169, ACU_loss:9.95065831)
epoch (21 / 50) (Loss:0.00503709, ACU_loss:9.88277081)
epoch (22 / 50) (Loss:0.00504780, ACU_loss:9.90378621)
epoch (23 / 50) (Loss:0.00506114, ACU_loss:9.92995716)
epoch (24 / 50) (Loss:0.00504371, ACU_loss:9.89575679)
epoch (25 / 50) (Loss:0.00508260, ACU_loss:9.97206461)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.2508591065292096
Precision: 0.874251497005988
Recall: 0.1464393179538616
Accuracy: 0.9495224312590449
AUC: 0.6856015891389613

Running seed 13...
Running seed 14...
Running seed 16...
Running seed 15...
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01057632, ACU_loss:20.75073378)
epoch (0 / 50) (Loss:0.01075339, ACU_loss:21.09814913)
epoch (0 / 50) (Loss:0.01199270, ACU_loss:23.52967233)
epoch (0 / 50) (Loss:0.01112536, ACU_loss:21.82794989)
epoch (1 / 50) (Loss:0.00505799, ACU_loss:9.92377389)
epoch (1 / 50) (Loss:0.00592263, ACU_loss:11.62020086)
epoch (1 / 50) (Loss:0.00535081, ACU_loss:10.49828915)
epoch (1 / 50) (Loss:0.00530826, ACU_loss:10.41481259)
epoch (2 / 50) (Loss:0.00582295, ACU_loss:11.42463666)
epoch (2 / 50) (Loss:0.00480794, ACU_loss:9.43317336)
epoch (2 / 50) (Loss:0.00465226, ACU_loss:9.12773079)
epoch (2 / 50) (Loss:0.00477038, ACU_loss:9.35947723)
epoch (3 / 50) (Loss:0.00587381, ACU_loss:11.52441345)
epoch (3 / 50) (Loss:0.00426321, ACU_loss:8.36441362)
epoch (3 / 50) (Loss:0.00452481, ACU_loss:8.87766831)
epoch (3 / 50) (Loss:0.00438643, ACU_loss:8.60617220)
epoch (4 / 50) (Loss:0.00613781, ACU_loss:12.04239301)
epoch (4 / 50) (Loss:0.00430484, ACU_loss:8.44610185)
epoch (4 / 50) (Loss:0.00455800, ACU_loss:8.94278990)
epoch (4 / 50) (Loss:0.00439203, ACU_loss:8.61716361)
epoch (5 / 50) (Loss:0.00625137, ACU_loss:12.26519649)
epoch (5 / 50) (Loss:0.00436603, ACU_loss:8.56616061)
epoch (5 / 50) (Loss:0.00454318, ACU_loss:8.91371760)
epoch (5 / 50) (Loss:0.00449874, ACU_loss:8.82651809)
epoch (6 / 50) (Loss:0.00611774, ACU_loss:12.00300198)
epoch (6 / 50) (Loss:0.00438057, ACU_loss:8.59467952)
epoch (6 / 50) (Loss:0.00472470, ACU_loss:9.26985866)
epoch (6 / 50) (Loss:0.00449735, ACU_loss:8.82380807)
epoch (7 / 50) (Loss:0.00628574, ACU_loss:12.33261937)
epoch (7 / 50) (Loss:0.00464096, ACU_loss:9.10557172)
epoch (7 / 50) (Loss:0.00468844, ACU_loss:9.19872770)
epoch (7 / 50) (Loss:0.00461621, ACU_loss:9.05699762)
epoch (8 / 50) (Loss:0.00648379, ACU_loss:12.72119076)
epoch (8 / 50) (Loss:0.00468675, ACU_loss:9.19540774)
epoch (8 / 50) (Loss:0.00461738, ACU_loss:9.05930493)
epoch (8 / 50) (Loss:0.00454815, ACU_loss:8.92347792)
epoch (9 / 50) (Loss:0.00631248, ACU_loss:12.38508485)
epoch (9 / 50) (Loss:0.00463640, ACU_loss:9.09660982)
epoch (9 / 50) (Loss:0.00478958, ACU_loss:9.39714692)
epoch (9 / 50) (Loss:0.00453780, ACU_loss:8.90315466)
epoch (10 / 50) (Loss:0.00629434, ACU_loss:12.34948771)
epoch (10 / 50) (Loss:0.00481767, ACU_loss:9.45226893)
epoch (10 / 50) (Loss:0.00471715, ACU_loss:9.25505755)
epoch (10 / 50) (Loss:0.00451462, ACU_loss:8.85769044)
epoch (11 / 50) (Loss:0.00626289, ACU_loss:12.28778495)
epoch (11 / 50) (Loss:0.00479800, ACU_loss:9.41366782)
epoch (11 / 50) (Loss:0.00488494, ACU_loss:9.58424454)
epoch (11 / 50) (Loss:0.00456349, ACU_loss:8.95357368)
epoch (12 / 50) (Loss:0.00645704, ACU_loss:12.66872217)
epoch (12 / 50) (Loss:0.00488009, ACU_loss:9.57473656)
epoch (12 / 50) (Loss:0.00470115, ACU_loss:9.22365174)
epoch (12 / 50) (Loss:0.00460313, ACU_loss:9.03134063)
epoch (13 / 50) (Loss:0.00630537, ACU_loss:12.37114351)
epoch (13 / 50) (Loss:0.00481053, ACU_loss:9.43826165)
epoch (13 / 50) (Loss:0.00471365, ACU_loss:9.24818553)
epoch (13 / 50) (Loss:0.00475154, ACU_loss:9.32251202)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.24804856895056374
Precision: 0.9166666666666666
Recall: 0.14343029087261785
Accuracy: 0.9498118668596237
AUC: 0.6222200820424167

epoch (14 / 50) (Loss:0.00641899, ACU_loss:12.59405018)
epoch (14 / 50) (Loss:0.00477086, ACU_loss:9.36042179)
epoch (14 / 50) (Loss:0.00481844, ACU_loss:9.45378799)
epoch (15 / 50) (Loss:0.00657735, ACU_loss:12.90475496)
epoch (15 / 50) (Loss:0.00470485, ACU_loss:9.23091915)
epoch (15 / 50) (Loss:0.00476123, ACU_loss:9.34153409)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.2622107969151671
Precision: 0.9
Recall: 0.1534603811434303
Accuracy: 0.9501591895803184
AUC: 0.6031760966644866

epoch (16 / 50) (Loss:0.00655100, ACU_loss:12.85307043)
epoch (16 / 50) (Loss:0.00470059, ACU_loss:9.22256095)
epoch (17 / 50) (Loss:0.00642482, ACU_loss:12.60550258)
epoch (17 / 50) (Loss:0.00462361, ACU_loss:9.07152829)
epoch (18 / 50) (Loss:0.00661287, ACU_loss:12.97444307)
epoch (18 / 50) (Loss:0.00461108, ACU_loss:9.04693029)
epoch (19 / 50) (Loss:0.00649133, ACU_loss:12.73598888)
epoch (19 / 50) (Loss:0.00465931, ACU_loss:9.14156085)
epoch (20 / 50) (Loss:0.00639531, ACU_loss:12.54758842)
epoch (20 / 50) (Loss:0.00463212, ACU_loss:9.08822543)
epoch (21 / 50) (Loss:0.00666910, ACU_loss:13.08477940)
epoch (21 / 50) (Loss:0.00467582, ACU_loss:9.17396716)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
/usr/local/venv/ugdn/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
=========================** Result **============================

F1 score: 0.0
Precision: 0.0
Recall: 0.0
Accuracy: 0.9422865412445731
AUC: 0.6485140394768283

epoch (22 / 50) (Loss:0.00466883, ACU_loss:9.16024094)
epoch (23 / 50) (Loss:0.00473165, ACU_loss:9.28350408)
epoch (24 / 50) (Loss:0.00478745, ACU_loss:9.39297788)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.12382739212007504
Precision: 0.9565217391304348
Recall: 0.06619859578736209
Accuracy: 0.9459334298118669
AUC: 0.6627824251720638

Running seed 17...
Running seed 18...
Running seed 19...
Running seed 20...
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01028736, ACU_loss:20.18379765)
epoch (0 / 50) (Loss:0.01050196, ACU_loss:20.60483759)
epoch (0 / 50) (Loss:0.01041238, ACU_loss:20.42909112)
epoch (0 / 50) (Loss:0.01048936, ACU_loss:20.58012795)
epoch (1 / 50) (Loss:0.00494051, ACU_loss:9.69328999)
epoch (1 / 50) (Loss:0.00619968, ACU_loss:12.16377867)
epoch (1 / 50) (Loss:0.00516615, ACU_loss:10.13598093)
epoch (1 / 50) (Loss:0.00511190, ACU_loss:10.02955725)
epoch (2 / 50) (Loss:0.00446365, ACU_loss:8.75768996)
epoch (2 / 50) (Loss:0.00607772, ACU_loss:11.92448059)
epoch (2 / 50) (Loss:0.00460206, ACU_loss:9.02924223)
epoch (2 / 50) (Loss:0.00475913, ACU_loss:9.33742006)
epoch (3 / 50) (Loss:0.00435780, ACU_loss:8.55000869)
epoch (3 / 50) (Loss:0.00427654, ACU_loss:8.39057998)
epoch (3 / 50) (Loss:0.00605269, ACU_loss:11.87538380)
epoch (3 / 50) (Loss:0.00436419, ACU_loss:8.56254384)
epoch (4 / 50) (Loss:0.00445345, ACU_loss:8.73766472)
epoch (4 / 50) (Loss:0.00440708, ACU_loss:8.64669685)
epoch (4 / 50) (Loss:0.00444837, ACU_loss:8.72770628)
epoch (4 / 50) (Loss:0.00592422, ACU_loss:11.62332010)
epoch (5 / 50) (Loss:0.00447014, ACU_loss:8.77040558)
epoch (5 / 50) (Loss:0.00431606, ACU_loss:8.46810785)
epoch (5 / 50) (Loss:0.00448386, ACU_loss:8.79732470)
epoch (5 / 50) (Loss:0.00597204, ACU_loss:11.71714596)
epoch (6 / 50) (Loss:0.00460089, ACU_loss:9.02693773)
epoch (6 / 50) (Loss:0.00435209, ACU_loss:8.53879247)
epoch (6 / 50) (Loss:0.00473647, ACU_loss:9.29295711)
epoch (6 / 50) (Loss:0.00606907, ACU_loss:11.90752281)
epoch (7 / 50) (Loss:0.00455058, ACU_loss:8.92823884)
epoch (7 / 50) (Loss:0.00444812, ACU_loss:8.72721766)
epoch (7 / 50) (Loss:0.00499155, ACU_loss:9.79342587)
epoch (7 / 50) (Loss:0.00597431, ACU_loss:11.72159355)
epoch (8 / 50) (Loss:0.00456661, ACU_loss:8.95969296)
epoch (8 / 50) (Loss:0.00443322, ACU_loss:8.69798390)
epoch (8 / 50) (Loss:0.00478658, ACU_loss:9.39126808)
epoch (8 / 50) (Loss:0.00593601, ACU_loss:11.64645761)
epoch (9 / 50) (Loss:0.00466020, ACU_loss:9.14331577)
epoch (9 / 50) (Loss:0.00466520, ACU_loss:9.15312334)
epoch (9 / 50) (Loss:0.00438005, ACU_loss:8.59365526)
epoch (9 / 50) (Loss:0.00593535, ACU_loss:11.64515454)
epoch (10 / 50) (Loss:0.00456633, ACU_loss:8.95913589)
epoch (10 / 50) (Loss:0.00469859, ACU_loss:9.21863596)
epoch (10 / 50) (Loss:0.00453316, ACU_loss:8.89405379)
epoch (10 / 50) (Loss:0.00600894, ACU_loss:11.78953739)
epoch (11 / 50) (Loss:0.00473243, ACU_loss:9.28503480)
epoch (11 / 50) (Loss:0.00482302, ACU_loss:9.46276440)
epoch (11 / 50) (Loss:0.00452587, ACU_loss:8.87975395)
epoch (11 / 50) (Loss:0.00614763, ACU_loss:12.06164330)
epoch (12 / 50) (Loss:0.00468362, ACU_loss:9.18925927)
epoch (12 / 50) (Loss:0.00480750, ACU_loss:9.43232443)
epoch (12 / 50) (Loss:0.00611603, ACU_loss:11.99965317)
epoch (12 / 50) (Loss:0.00458456, ACU_loss:8.99490103)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.17048579285059579
Precision: 0.9893617021276596
Recall: 0.09327983951855567
Accuracy: 0.9476121562952243
AUC: 0.6026927693018853

=========================** Result **============================

F1 score: 0.22418358340688438
Precision: 0.9338235294117647
Recall: 0.12738214643931794
Accuracy: 0.9491172214182344
AUC: 0.7006468477801016

epoch (13 / 50) (Loss:0.00480896, ACU_loss:9.43518892)
epoch (13 / 50) (Loss:0.00612993, ACU_loss:12.02691990)
epoch (14 / 50) (Loss:0.00482251, ACU_loss:9.46177230)
epoch (14 / 50) (Loss:0.00623212, ACU_loss:12.22741379)
epoch (15 / 50) (Loss:0.00503239, ACU_loss:9.87355177)
epoch (15 / 50) (Loss:0.00630316, ACU_loss:12.36679962)
epoch (16 / 50) (Loss:0.00493268, ACU_loss:9.67791198)
epoch (16 / 50) (Loss:0.00635264, ACU_loss:12.46387112)
epoch (17 / 50) (Loss:0.00505366, ACU_loss:9.91528471)
epoch (17 / 50) (Loss:0.00619871, ACU_loss:12.16186661)
epoch (18 / 50) (Loss:0.00543962, ACU_loss:10.67254275)
epoch (18 / 50) (Loss:0.00633363, ACU_loss:12.42658271)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.1308411214953271
Precision: 0.958904109589041
Recall: 0.07021063189568706
Accuracy: 0.9461649782923299
AUC: 0.6319929194143433

epoch (19 / 50) (Loss:0.00519151, ACU_loss:10.18575106)
epoch (20 / 50) (Loss:0.00513314, ACU_loss:10.07122192)
epoch (21 / 50) (Loss:0.00508798, ACU_loss:9.98262610)
epoch (22 / 50) (Loss:0.00518311, ACU_loss:10.16927046)
epoch (23 / 50) (Loss:0.00531520, ACU_loss:10.42841803)
epoch (24 / 50) (Loss:0.00505159, ACU_loss:9.91122647)
epoch (25 / 50) (Loss:0.00536187, ACU_loss:10.51998689)
epoch (26 / 50) (Loss:0.00512664, ACU_loss:10.05846719)
epoch (27 / 50) (Loss:0.00506273, ACU_loss:9.93307006)
epoch (28 / 50) (Loss:0.00525208, ACU_loss:10.30458030)
epoch (29 / 50) (Loss:0.00513244, ACU_loss:10.06985051)
epoch (30 / 50) (Loss:0.00500209, ACU_loss:9.81409857)
/home/mskim2/GDN/main.py:124: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.model.load_state_dict(torch.load(model_save_path))
=========================** Result **============================

F1 score: 0.2622107969151671
Precision: 0.9
Recall: 0.1534603811434303
Accuracy: 0.9501591895803184
AUC: 0.598713760152555

Running seed 21...
Running seed 22...
Running seed 23...
Running seed 24...
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
/home/mskim2/GDN/models/GDN.py:205: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3683.)
  gated_i = torch.arange(0, node_num).T.unsqueeze(1).repeat(1, topk_num).flatten().to(device).unsqueeze(0)
epoch (0 / 50) (Loss:0.01024638, ACU_loss:20.10339064)
epoch (0 / 50) (Loss:0.01038300, ACU_loss:20.37143901)
epoch (0 / 50) (Loss:0.01239831, ACU_loss:24.32548637)
epoch (0 / 50) (Loss:0.01054262, ACU_loss:20.68462569)
epoch (1 / 50) (Loss:0.00504135, ACU_loss:9.89113549)
epoch (1 / 50) (Loss:0.00502280, ACU_loss:9.85472996)
epoch (1 / 50) (Loss:0.00645417, ACU_loss:12.66309035)
epoch (1 / 50) (Loss:0.00617299, ACU_loss:12.11140110)
epoch (2 / 50) (Loss:0.00462561, ACU_loss:9.07545341)
epoch (2 / 50) (Loss:0.00575840, ACU_loss:11.29798170)
epoch (2 / 50) (Loss:0.00635238, ACU_loss:12.46336518)
epoch (2 / 50) (Loss:0.00585902, ACU_loss:11.49539538)
epoch (3 / 50) (Loss:0.00586891, ACU_loss:11.51479214)
epoch (3 / 50) (Loss:0.00432695, ACU_loss:8.48947604)
epoch (3 / 50) (Loss:0.00628403, ACU_loss:12.32926717)
epoch (3 / 50) (Loss:0.00575356, ACU_loss:11.28848381)
epoch (4 / 50) (Loss:0.00604435, ACU_loss:11.85901380)
epoch (4 / 50) (Loss:0.00623559, ACU_loss:12.23423442)
epoch (4 / 50) (Loss:0.00425069, ACU_loss:8.33985717)
epoch (4 / 50) (Loss:0.00579874, ACU_loss:11.37713600)
epoch (5 / 50) (Loss:0.00597400, ACU_loss:11.72098664)
epoch (5 / 50) (Loss:0.00634981, ACU_loss:12.45831850)
epoch (5 / 50) (Loss:0.00417812, ACU_loss:8.19746982)
epoch (5 / 50) (Loss:0.00592090, ACU_loss:11.61680146)
epoch (6 / 50) (Loss:0.00602936, ACU_loss:11.82959569)
epoch (6 / 50) (Loss:0.00627767, ACU_loss:12.31679713)
epoch (6 / 50) (Loss:0.00452277, ACU_loss:8.87366779)
epoch (6 / 50) (Loss:0.00609114, ACU_loss:11.95082157)
epoch (7 / 50) (Loss:0.00622205, ACU_loss:12.20767187)
epoch (7 / 50) (Loss:0.00641130, ACU_loss:12.57897792)
epoch (7 / 50) (Loss:0.00448570, ACU_loss:8.80094020)
epoch (7 / 50) (Loss:0.00595261, ACU_loss:11.67902726)
epoch (8 / 50) (Loss:0.00621480, ACU_loss:12.19343391)
epoch (8 / 50) (Loss:0.00635536, ACU_loss:12.46922235)
epoch (8 / 50) (Loss:0.00458405, ACU_loss:8.99391462)
epoch (8 / 50) (Loss:0.00608709, ACU_loss:11.94287723)
